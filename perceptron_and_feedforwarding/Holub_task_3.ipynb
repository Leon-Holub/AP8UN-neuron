{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaKvxTNG19jB"
   },
   "source": [
    "The detailed Perceptron mechanisms see in assignment 2 this course and assignment we're going to use existing frameworks to impliment the perceptron and feedforward neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CTJ9bgf2pzI"
   },
   "source": [
    "sklearn and iris dataset--the small and classic dataset for machine learning, shows the basic of the a dataset has--features, labels and samples"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vExLG4Da1oQ6",
    "outputId": "205c55bb-690f-4c3b-e414-4617b50896e6",
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:13.557598Z",
     "start_time": "2025-03-27T08:25:13.526232Z"
    }
   },
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris=load_iris()\n",
    "print(iris.data.shape)\n",
    "iris"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 150 (50 in each of three classes)\\n:Number of Attributes: 4 numeric, predictive attributes and the class\\n:Attribute Information:\\n    - sepal length in cm\\n    - sepal width in cm\\n    - petal length in cm\\n    - petal width in cm\\n    - class:\\n            - Iris-Setosa\\n            - Iris-Versicolour\\n            - Iris-Virginica\\n\\n:Summary Statistics:\\n\\n============== ==== ==== ======= ===== ====================\\n                Min  Max   Mean    SD   Class Correlation\\n============== ==== ==== ======= ===== ====================\\nsepal length:   4.3  7.9   5.84   0.83    0.7826\\nsepal width:    2.0  4.4   3.05   0.43   -0.4194\\npetal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\npetal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n============== ==== ==== ======= ===== ====================\\n\\n:Missing Attribute Values: None\\n:Class Distribution: 33.3% for each of 3 classes.\\n:Creator: R.A. Fisher\\n:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n:Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. dropdown:: References\\n\\n  - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n    Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n    Mathematical Statistics\" (John Wiley, NY, 1950).\\n  - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n    (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n  - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n    Structure and Classification Rule for Recognition in Partially Exposed\\n    Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n    Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n  - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n    on Information Theory, May 1972, 431-433.\\n  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n    conceptual clustering system finds 3 classes in the data.\\n  - Many, many more ...\\n',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWwjgGe8HBcO",
    "outputId": "059f57b3-c284-42cb-cfa5-7aca79e3cf76",
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:13.604956Z",
     "start_time": "2025-03-27T08:25:13.573465Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "# Add the target column\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Display the first few rows\n",
    "print(df) # df.head() / df.tail()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                  5.1               3.5                1.4               0.2   \n",
      "1                  4.9               3.0                1.4               0.2   \n",
      "2                  4.7               3.2                1.3               0.2   \n",
      "3                  4.6               3.1                1.5               0.2   \n",
      "4                  5.0               3.6                1.4               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "145                6.7               3.0                5.2               2.3   \n",
      "146                6.3               2.5                5.0               1.9   \n",
      "147                6.5               3.0                5.2               2.0   \n",
      "148                6.2               3.4                5.4               2.3   \n",
      "149                5.9               3.0                5.1               1.8   \n",
      "\n",
      "     target  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "..      ...  \n",
      "145       2  \n",
      "146       2  \n",
      "147       2  \n",
      "148       2  \n",
      "149       2  \n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "id": "YTIziUnh41MG",
    "outputId": "45de6365-91aa-4465-df88-9d31f5129eca",
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:13.979957Z",
     "start_time": "2025-03-27T08:25:13.648077Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling (important for neural networks)\n",
    "scaler = StandardScaler() # MinMaxScaler() (Normalization)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build and train the neural network\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=500, random_state=42) # MLPClassifier(hidden_layer_sizes=(10, 20,10) 3 hidden layers and their neuron numbers\n",
    "# loss cross entropy for classifier and MSE for MLPRegressor\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Plot some of the test results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, marker='o', label='True Labels')\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred, marker='x', label='Predicted Labels')\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Sepal width\")\n",
    "plt.title('Iris Dataset Classification')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leonh\\OneDrive\\Dokumenty\\skola\\Ing\\2.semestr\\neuron\\.venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-entropy loss is a common loss function used in classification tasks, especially in neural networks. It measures the difference between two probability distributions: the predicted probabilities (output by the model) and the true distribution (ground truth labels). The goal of training is to minimize this loss, which corresponds to making the predicted probabilities as close as possible to the true distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For binary classification)Binary Cross-Entropy Loss = (-1/n)∑[y_i.log(p_i)+(1-y_i).log(1-p_i)]\n",
    "Where\n",
    "\n",
    "n: Number of samples.\n",
    "\n",
    "y_i: True label for sample i (0 or 1).\n",
    "\n",
    "p_i: Predicted probability for sample i (between 0 and 1).\n",
    "\n",
    "(For multi-class classification)Categorical Cross-Entropy Loss = (-1/n)∑∑y_i_c.log(p_i_c)\n",
    "\n",
    "Where:\n",
    "\n",
    "n: Number of samples.\n",
    "c: Number of classes.\n",
    "y_i_c: True label for sample i and class c (one-hot encoded: 1 if the sample belongs to class c, otherwise 0).\n",
    "p_i_c: Predicted probability for sample i and class c.\n",
    "\n",
    "Why Use Cross-Entropy?\n",
    "\n",
    "It penalizes incorrect predictions more heavily when the predicted probability is far from the true label.\n",
    "\n",
    "It works well with softmax activation in the output layer, which converts raw scores (logits) into probabilities.\n",
    "\n",
    "Step 1: Binary Cross-Entropy (From Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNssOG0X93O9",
    "outputId": "f18d8b8a-e510-4f55-e7d2-e4410a02e185",
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.027663Z",
     "start_time": "2025-03-27T08:25:14.011638Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "def binary_cross_entropy_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute binary cross-entropy loss manually.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (numpy array): True labels (0 or 1), shape (N,).\n",
    "        y_pred (numpy array): Predicted probabilities (between 0 and 1), shape (N,).\n",
    "\n",
    "    Returns:\n",
    "        float: Mean binary cross-entropy loss.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-7  # Small value to avoid log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip values to prevent numerical instability\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "# Example Usage\n",
    "y_true = np.array([1, 0, 1, 1, 0])  # True labels\n",
    "y_pred = np.array([0.9, 0.1, 0.8, 0.7, 0.2])  # Predicted probabilities\n",
    "\n",
    "loss = binary_cross_entropy_loss(y_true, y_pred)\n",
    "print(f\"Manually Calculated Binary Cross-Entropy Loss: {loss:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually Calculated Binary Cross-Entropy Loss: 0.2027\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Categorical Cross-Entropy (From Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFOkQqPh9-cb",
    "outputId": "045fbc45-9e27-459c-f7c8-0f51ac3a8fc0",
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.074590Z",
     "start_time": "2025-03-27T08:25:14.061619Z"
    }
   },
   "source": [
    "def categorical_cross_entropy_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute categorical cross-entropy loss manually.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (numpy array): True labels (one-hot encoded), shape (N, C).\n",
    "        y_pred (numpy array): Predicted probabilities, shape (N, C).\n",
    "\n",
    "    Returns:\n",
    "        float: Mean categorical cross-entropy loss.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-7  # Small value to avoid log(0)\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)  # Clip values to prevent numerical instability\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred), axis=1))  # Sum over classes, then mean over samples\n",
    "    return loss\n",
    "\n",
    "# Example Usage\n",
    "y_true = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])  # One-hot encoded true labels\n",
    "y_pred = np.array([[0.8, 0.1, 0.1], [0.2, 0.7, 0.1], [0.1, 0.2, 0.7]])  # Predicted probabilities\n",
    "\n",
    "loss = categorical_cross_entropy_loss(y_true, y_pred)\n",
    "print(f\"Manually Calculated Categorical Cross-Entropy Loss: {loss:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually Calculated Categorical Cross-Entropy Loss: 0.3122\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmNikqRe-JHd"
   },
   "source": [
    "Step 3: Comparison with PyTorch's Built-In Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgP4Bsla-J08",
    "outputId": "fb7d2abc-85f8-4861-d894-ea245225a1ee",
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.129457Z",
     "start_time": "2025-03-27T08:25:14.110601Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Binary Cross-Entropy Loss in PyTorch\n",
    "bce_loss_fn = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "y_true_tensor = torch.tensor([1.0, 0.0, 1.0, 1.0, 0.0])  # True labels\n",
    "y_pred_tensor = torch.tensor([0.9, 0.1, 0.8, 0.7, 0.2])  # Predicted probabilities\n",
    "bce_loss = bce_loss_fn(y_pred_tensor, y_true_tensor)\n",
    "print(f\"PyTorch Binary Cross-Entropy Loss: {bce_loss.item():.4f}\")\n",
    "\n",
    "# Categorical Cross-Entropy Loss in PyTorch\n",
    "cce_loss_fn = nn.CrossEntropyLoss()  # Categorical Cross-Entropy Loss\n",
    "y_true_tensor = torch.tensor([0, 1, 2])  # Class indices (not one-hot encoded)\n",
    "y_pred_tensor = torch.tensor([[2.0, -1.0, -1.0], [-1.0, 2.0, -1.0], [-1.0, -1.0, 2.0]])  # Raw logits\n",
    "cce_loss = cce_loss_fn(y_pred_tensor, y_true_tensor)\n",
    "print(f\"PyTorch Categorical Cross-Entropy Loss: {cce_loss.item():.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Binary Cross-Entropy Loss: 0.2027\n",
      "PyTorch Categorical Cross-Entropy Loss: 0.0949\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vywc-mq_uxK"
   },
   "source": [
    "The gradient of the loss with respect to the weights w is:\n",
    "\n",
    "∂w/∂L = (1/N)∑(p_i−y_i)⋅x_i\n",
    "\n",
    "Where:\n",
    "\n",
    "p_i-y_i: Difference between predicted probabilities and true labels.\n",
    "\n",
    "Gradient Descent Update Rule:\n",
    "\n",
    "w:=w-η⋅∂L/∂w\n",
    "\n",
    "where:\n",
    "\n",
    "η: Learning rate.\n",
    "\n",
    "Adam Optimizer Update Rule:\n",
    "\n",
    "Adam combines momentum and adaptive learning rates. The update rules are:\n",
    "\n",
    "1 Compute the first moment (mean of gradients):\n",
    "\n",
    "m_t= β1⋅m_(t-1)+(1-β1)⋅g_t\n",
    "\n",
    "2 Compute the second moment (uncentered variance of gradients):\n",
    "\n",
    "v_t=β2⋅v_(t-1)+(1-β2)⋅(g_t)^2\n",
    "\n",
    "3 Bias correction:\n",
    "\n",
    "M_t=m_t/(1-β1_t)\n",
    "\n",
    "V_t=v_t/(1-β2_t)​\n",
    "\n",
    "Update the weights:\n",
    "\n",
    "w:=w-η⋅M_t/((√V_t)+ϵ)\n",
    "\n",
    "Where:\n",
    "\n",
    "g_t: Gradient at time step t.\n",
    "\n",
    "β1,β2: Exponential decay rates for the first and second moments (default: 0.9, 0.999).\n",
    "\n",
    "ϵ: Small constant to prevent division by zero (default: 1e-8).\n",
    "\n",
    "Binary Cross-Entropy Loss with Gradient Descent:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWDHJiP2F5Vl",
    "outputId": "afe30cb4-ef78-48e9-8eae-33325d81d9cf",
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.224106Z",
     "start_time": "2025-03-27T08:25:14.184168Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def binary_cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "def gradient_descent_binary(X, y, learning_rate=0.01, epochs=100):\n",
    "    \"\"\"\n",
    "    Perform gradient descent for binary classification using binary cross-entropy loss.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy array): Input features, shape (N, D).\n",
    "        y (numpy array): True labels (0 or 1), shape (N,).\n",
    "        learning_rate (float): Learning rate.\n",
    "        epochs (int): Number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        weights (numpy array): Learned weights.\n",
    "        losses (list): Loss values over epochs.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    weights = np.zeros(D)  # Initialize weights to zero\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        z = np.dot(X, weights)\n",
    "        y_pred = sigmoid(z)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = binary_cross_entropy_loss(y, y_pred)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = (1 / N) * np.dot(X.T, (y_pred - y))\n",
    "\n",
    "        # Update weights\n",
    "        weights -= learning_rate * gradients\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return weights, losses\n",
    "\n",
    "# Example Usage\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])  # Input features\n",
    "y = np.array([0, 0, 1, 1])  # True labels\n",
    "weights, losses = gradient_descent_binary(X, y, learning_rate=0.1, epochs=100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931\n",
      "Epoch 10, Loss: 0.6348\n",
      "Epoch 20, Loss: 0.6246\n",
      "Epoch 30, Loss: 0.6146\n",
      "Epoch 40, Loss: 0.6049\n",
      "Epoch 50, Loss: 0.5955\n",
      "Epoch 60, Loss: 0.5863\n",
      "Epoch 70, Loss: 0.5774\n",
      "Epoch 80, Loss: 0.5688\n",
      "Epoch 90, Loss: 0.5604\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZ0CFiJWGJko"
   },
   "source": [
    "Categorical Cross-Entropy Loss with Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-Jp4HlSGKd9",
    "outputId": "c5fde0aa-3d22-4524-bc7a-be3c0ce4b46c",
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.320236Z",
     "start_time": "2025-03-27T08:25:14.294842Z"
    }
   },
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  # Numerical stability\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def categorical_cross_entropy_loss(y_true, y_pred):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "    return loss\n",
    "\n",
    "def adam_optimizer_categorical(X, y, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8, epochs=100):\n",
    "    \"\"\"\n",
    "    Perform Adam optimization for multi-class classification using categorical cross-entropy loss.\n",
    "\n",
    "    Parameters:\n",
    "        X (numpy array): Input features, shape (N, D).\n",
    "        y (numpy array): One-hot encoded true labels, shape (N, C).\n",
    "        learning_rate (float): Learning rate.\n",
    "        beta1, beta2 (float): Exponential decay rates for Adam.\n",
    "        epsilon (float): Small constant to prevent division by zero.\n",
    "        epochs (int): Number of iterations.\n",
    "\n",
    "    Returns:\n",
    "        weights (numpy array): Learned weights.\n",
    "        losses (list): Loss values over epochs.\n",
    "    \"\"\"\n",
    "    N, D = X.shape\n",
    "    _, C = y.shape\n",
    "    weights = np.zeros((D, C))  # Initialize weights to zero\n",
    "    m = np.zeros_like(weights)  # First moment vector\n",
    "    v = np.zeros_like(weights)  # Second moment vector\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        z = np.dot(X, weights)\n",
    "        y_pred = softmax(z)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = categorical_cross_entropy_loss(y, y_pred)\n",
    "        losses.append(loss)\n",
    "\n",
    "        # Compute gradients\n",
    "        gradients = (1 / N) * np.dot(X.T, (y_pred - y))\n",
    "\n",
    "        # Update first and second moments\n",
    "        m = beta1 * m + (1 - beta1) * gradients\n",
    "        v = beta2 * v + (1 - beta2) * gradients**2\n",
    "\n",
    "        # Bias correction\n",
    "        m_hat = m / (1 - beta1**(epoch + 1))\n",
    "        v_hat = v / (1 - beta2**(epoch + 1))\n",
    "\n",
    "        # Update weights\n",
    "        weights -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return weights, losses\n",
    "\n",
    "# Example Usage\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])  # Input features\n",
    "y = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0]])  # One-hot encoded true labels\n",
    "weights, losses = adam_optimizer_categorical(X, y, learning_rate=0.01, epochs=100)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.0986\n",
      "Epoch 10, Loss: 1.0432\n",
      "Epoch 20, Loss: 1.0402\n",
      "Epoch 30, Loss: 1.0369\n",
      "Epoch 40, Loss: 1.0335\n",
      "Epoch 50, Loss: 1.0313\n",
      "Epoch 60, Loss: 1.0288\n",
      "Epoch 70, Loss: 1.0263\n",
      "Epoch 80, Loss: 1.0239\n",
      "Epoch 90, Loss: 1.0216\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My code"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.336326Z",
     "start_time": "2025-03-27T08:25:14.327279Z"
    }
   },
   "source": [
    "def load_and_preprocess_data():\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    print(f\"Number of features: {X.shape[1]}\")\n",
    "    print(f\"Number of classes: {len(set(y))}\")\n",
    "\n",
    "    X_perceptron, y_perceptron = X[y < 2], y[y < 2]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_perceptron, y_perceptron, test_size=0.2,\n",
    "                                                                random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    return {\n",
    "        \"X_train\": scaler.fit_transform(X_train), \"X_test\": scaler.transform(X_test),\n",
    "        \"y_train\": y_train, \"y_test\": y_test,\n",
    "        \"X_train_p\": scaler.fit_transform(X_train_p), \"X_test_p\": scaler.transform(X_test_p),\n",
    "        \"y_train_p\": y_train_p, \"y_test_p\": y_test_p\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.404678Z",
     "start_time": "2025-03-27T08:25:14.382675Z"
    }
   },
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "\n",
    "def train_perceptron(X_train_p, X_test_p, y_train_p, y_test_p):\n",
    "    model = Perceptron()\n",
    "    model.fit(X_train_p, y_train_p)\n",
    "    y_pred = model.predict(X_test_p)\n",
    "    print(\"Scikit-learn Perceptron:\")\n",
    "    print(classification_report(y_test_p, y_pred))"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.495851Z",
     "start_time": "2025-03-27T08:25:14.471504Z"
    }
   },
   "source": [
    "data = load_and_preprocess_data()\n",
    "train_perceptron(data['X_train_p'], data['X_test_p'], data['y_train_p'], data['y_test_p'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4\n",
      "Number of classes: 3\n",
      "Scikit-learn Perceptron:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:14.831980Z",
     "start_time": "2025-03-27T08:25:14.529418Z"
    }
   },
   "source": [
    "def train_sklearn_feedforward(X_train, X_test, y_train, y_test):\n",
    "    model = MLPClassifier(hidden_layer_sizes=(10,), activation='relu', solver='adam', max_iter=10000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Scikit-learn Feedforward NN:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "train_sklearn_feedforward(data['X_train'], data['X_test'], data['y_train'], data['y_test'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Feedforward NN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:16.918767Z",
     "start_time": "2025-03-27T08:25:14.864075Z"
    }
   },
   "source": [
    "from keras.src.layers import Dense\n",
    "from keras.src.layers import Dropout\n",
    "from keras import Sequential\n",
    "\n",
    "from keras import Input\n",
    "\n",
    "\n",
    "def train_keras_feedforward(X_train, X_test, y_train, y_test):\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=30, verbose=0)\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    print(\"Keras Feedforward NN:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "train_keras_feedforward(data['X_train'], data['X_test'], data['y_train'], data['y_test'])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step\n",
      "Keras Feedforward NN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        10\n",
      "           1       0.38      0.67      0.48         9\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.38      0.56      0.45        30\n",
      "weighted avg       0.37      0.53      0.43        30\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:16.962732Z",
     "start_time": "2025-03-27T08:25:16.949179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, activation_fn):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = activation_fn\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:17.024132Z",
     "start_time": "2025-03-27T08:25:16.998885Z"
    }
   },
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_pytorch_feedforward(X_train, X_test, y_train, y_test, activation, optimizer_type):\n",
    "    X_train_torch = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_torch = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test_torch = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_torch = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "    dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "    model = FeedforwardNN(X_train.shape[1], 10, 3, activation)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if optimizer_type == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    elif optimizer_type == 'SGD':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown optimizer: {optimizer_type}')\n",
    "\n",
    "    for epoch in range(30):\n",
    "        for batch in dataloader:\n",
    "            inputs, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    y_pred = torch.argmax(model(X_test_torch), axis=1).detach().cpu().numpy()\n",
    "    y_true = y_test_torch.detach().cpu().numpy()\n",
    "    print(classification_report(y_true, y_pred))\n"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:17.571407Z",
     "start_time": "2025-03-27T08:25:17.056428Z"
    }
   },
   "source": [
    "print(\"PyTorch Feedforward NN (Activation: ReLU, Optimizer: Adam):\")\n",
    "train_pytorch_feedforward(data['X_train'], data['X_test'], data['y_train'], data['y_test'], nn.ReLU(),\"Adam\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Feedforward NN (Activation: ReLU, Optimizer: Adam):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:17.999698Z",
     "start_time": "2025-03-27T08:25:17.603407Z"
    }
   },
   "source": [
    "print(\"PyTorch Feedforward NN (Activation: ReLU, Optimizer: SGD):\")\n",
    "train_pytorch_feedforward(data['X_train'], data['X_test'], data['y_train'], data['y_test'], nn.ReLU(),\"SGD\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Feedforward NN (Activation: ReLU, Optimizer: SGD):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.75      0.67      0.71         9\n",
      "           2       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.83        30\n",
      "   macro avg       0.84      0.83      0.83        30\n",
      "weighted avg       0.84      0.83      0.83        30\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:18.578241Z",
     "start_time": "2025-03-27T08:25:18.031443Z"
    }
   },
   "source": [
    "print(\"PyTorch Feedforward NN (Activation: Sigmoid, Optimizer: Adam):\")\n",
    "train_pytorch_feedforward(data['X_train'], data['X_test'], data['y_train'], data['y_test'], nn.Sigmoid(),\"Adam\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Feedforward NN (Activation: Sigmoid, Optimizer: Adam):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.88      0.78      0.82         9\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.90      0.90      0.90        30\n",
      "weighted avg       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:19.090287Z",
     "start_time": "2025-03-27T08:25:18.644043Z"
    }
   },
   "source": [
    "print(\"PyTorch Feedforward NN (Activation: Sigmoid, Optimizer: SGD):\")\n",
    "train_pytorch_feedforward(data['X_train'], data['X_test'], data['y_train'], data['y_test'], nn.Sigmoid(),\"SGD\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Feedforward NN (Activation: Sigmoid, Optimizer: SGD):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        10\n",
      "           1       0.60      0.33      0.43         9\n",
      "           2       0.60      0.82      0.69        11\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.70      0.68      0.67        30\n",
      "weighted avg       0.70      0.70      0.68        30\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:19.668593Z",
     "start_time": "2025-03-27T08:25:19.137353Z"
    }
   },
   "source": [
    "print(\"PyTorch Feedforward NN (Activation: Tanh, Optimizer: Adam):\")\n",
    "train_pytorch_feedforward(data['X_train'], data['X_test'], data['y_train'], data['y_test'], nn.Tanh(),\"Adam\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Feedforward NN (Activation: Tanh, Optimizer: Adam):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T08:25:20.129974Z",
     "start_time": "2025-03-27T08:25:19.700212Z"
    }
   },
   "source": [
    "print(\"PyTorch Feedforward NN (Activation: Tanh, Optimizer: SGD):\")\n",
    "train_pytorch_feedforward(data['X_train'], data['X_test'], data['y_train'], data['y_test'], nn.Tanh(),\"SGD\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Feedforward NN (Activation: Tanh, Optimizer: SGD):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.89      0.94         9\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "## 1) What’s the difference between perceptron and feedforward network?\n",
    "A perceptron is a simple binary classifier that can only handle linearly separable data.\n",
    "A feedforward neural network has multiple layers, uses non-linear activation functions, and can learn complex patterns in data.\n",
    "\n",
    "## 2) Sklearn, Keras, and PyTorch – which is the best?\n",
    "It depends on the specific use case and requirements.\n",
    "Scikit-learn is great for traditional machine learning tasks and has a wide range of algorithms.\n",
    "Keras is user-friendly and designed for quick prototyping of neural networks.\n",
    "PyTorch is more flexible and widely used in research and production settings.\n",
    "\n",
    "## 3) Which optimizers were used and why?\n",
    "Adam and SGD optimizers were used in the PyTorch implementation.\n",
    "Adam - Fast and adaptive, but can get stuck in suboptimal solutions\n",
    "SGD - Slower, but can generalize better\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
