# ðŸ§  Convolutional Neural Networks Projects

Welcome! This report presents three creative CNN-based image classification projects. Each section includes an introduction, model summary, accuracy metrics, and example predictions.

---

## ðŸ“Œ Navigation

- [1. Cats vs Dogs](#1-cats-vs-dogs)
- [2. Hotdog or Not](#2-hotdog-or-not)
- [3. Rock Paper Scissors](#3-rock-paper-scissors)

---

## 1. Cats vs Dogs

> ðŸ¶ðŸ± Binary classification project to distinguish between cats and dogs using deep transfer learning.

### ðŸ§  Model Overview
This project uses **MobileNetV2**, a pre-trained convolutional neural network designed for image classification tasks. Instead of training a CNN from scratch, we use this model as a **feature extractor** and train only a small classification head on top.

#### Architecture:
- **Base model:** MobileNetV2 (pre-trained on ImageNet, frozen)
- **Input size:** 224 Ã— 224 Ã— 3
- **Top layers:**
  - `GlobalAveragePooling2D`
  - `Dropout(0.3)`
  - `Dense(1, activation='sigmoid')`
- **Optimizer:** Adam
- **Loss:** Binary cross-entropy
- **Callbacks:** EarlyStopping and ReduceLROnPlateau

---

### ðŸ“Š Training Results

Training was performed for **15 epochs**, using data augmentation and validation split of 20%. The model quickly reached high accuracy and generalization:

| Metric         | Value       |
|----------------|-------------|
| Train accuracy | **~99.5%**  |
| Val accuracy   | **~94.5%**  |
| Epochs         | 15          |

---

### ðŸ“ˆ Accuracy Graph

Accuracy for training and validation over epochs:

![Cats vs Dogs Accuracy](cats_and_dogs/charts/accuracy.png)

---

### ðŸ“ƒ Training Logs (Epochs)

Here is a snapshot of the training progress during the epochs:

![Epoch Logs](cats_and_dogs/charts/epochs.png)

---

### ðŸ“¸ Example Predictions

The model performs very well in identifying both dogs and cats in unseen data. Below are five test samples with predictions:

![Sample Predictions](cats_and_dogs/charts/sample.png)

> âœ… The model correctly identifies dogs and cats with high confidence. Even images with unusual lighting or angles are correctly classified.

---

## 2. Hotdog or Not

> ðŸŒ­âŒ A fun binary classification task inspired by the classic â€œhotdog or notâ€ meme.

### ðŸ§  Model Overview
We use **MobileNetV2** again as a base model and freeze its layers to serve as a feature extractor. The final classification is done through a small custom head.

#### Architecture:
- **Base model:** MobileNetV2 (frozen)
- **Input size:** 224 Ã— 224 Ã— 3
- **Top layers:**
  - `GlobalAveragePooling2D`
  - `Dropout(0.5)`
  - `Dense(64, activation='relu')`
  - `Dropout(0.3)`
  - `Dense(1, activation='sigmoid')`
- **Optimizer:** Adam
- **Loss:** Binary cross-entropy
- **Callbacks:** EarlyStopping

---

### ðŸ“Š Training Results

| Metric         | Value       |
|----------------|-------------|
| Train accuracy | **~90.1%**  |
| Val accuracy   | **~92.4%**  |
| Epochs         | 7           |

The model converged quickly with high validation accuracy thanks to data augmentation and transfer learning.

---

### ðŸ“ˆ Accuracy Graph

![Hotdog Accuracy](hotdog_or_not/charts/accuracy.png)

---

### ðŸ“ƒ Training Logs (Epochs)

![Epoch Logs](hotdog_or_not/charts/epochs.png)

---

### ðŸ“¸ Example Predictions

The following test samples show the modelâ€™s ability to identify hotdogs:

![Hotdog Samples](hotdog_or_not/charts/sample.png)

> ðŸ” The model achieved excellent accuracy. Only one image was misclassified, but overall performance was very strong.

---

## 3. Rock Paper Scissors

> âœŠâœ‹âœŒï¸ Multi-class image classification of hand gestures from the classic game.

### ðŸ§  Model Overview
A custom CNN model was built from scratch for this task, capable of distinguishing between **rock**, **paper**, and **scissors**. Data augmentation and dropout layers help with generalization.

#### Architecture:
- **Input size:** 100 Ã— 100 Ã— 3
- **Conv blocks:**
  - `Conv2D + BatchNorm + MaxPooling + Dropout` Ã— 3
- **Dense head:**
  - `Flatten â†’ Dense(256) â†’ Dropout(0.4) â†’ Dense(3, softmax)`
- **Optimizer:** Adam
- **Loss:** Categorical cross-entropy
- **Callbacks:** EarlyStopping

---

### ðŸ“Š Training Results

| Metric         | Value       |
|----------------|-------------|
| Train accuracy | **~99.6%**  |
| Val accuracy   | **~97.7%**  |
| Epochs         | 12          |

The model performed extremely well even on a small input size, due to effective data preprocessing and a well-structured architecture.

---

### ðŸ“ˆ Accuracy Graph

![RPS Accuracy](rock_paper_scissors/charts/accuracy.png)

---

### ðŸ“ƒ Training Logs (Epochs)

![RPS Logs](rock_paper_scissors/charts/epochs.png)

---

### ðŸ“¸ Example Predictions

Below are some test images with predicted vs. actual labels:

![RPS Predictions](rock_paper_scissors/charts/sample.png)

> âœ¨ The classifier shows excellent accuracy across all three classes. It reliably detects each hand gesture even with different hand shapes and lighting conditions.

---